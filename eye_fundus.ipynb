{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "#import models.cifar as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#choose gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "augment_root = '/home/userpython3/Templates/health/Xli/eye_data/augment_train/'\n",
    "train_data_root = ''\n",
    "test_data_root = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs = os.listdir(pick_root + '3/')\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs[0].split('.')[-2].split('_')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Eye(data.Dataset):\n",
    "    def __init__(self, root,transforms = None, train = True, test = False):\n",
    "        self.test = test\n",
    "        imgs = []\n",
    "        if self.test:\n",
    "            imgs = [os.path.join(root,img) for img in os.listdir(root)]\n",
    "        else:    \n",
    "            labels = os.listdir(root)\n",
    "            for i in range(len(labels)):\n",
    "                img_temp = [os.path.join(root,labels[i], img) for img in os.listdir(os.path.join(root, labels[i]))]\n",
    "                imgs = imgs + img_temp\n",
    "\n",
    "            imgs = sorted(imgs, key=lambda x: int(x.split('/')[-1].split('.')[-2].split('_')[-2]))\n",
    "        imgs_num = len(imgs)\n",
    "        if self.test:\n",
    "            self.imgs = imgs\n",
    "        elif train:\n",
    "            self.imgs = imgs[:int(0.8 * imgs_num)]\n",
    "        else:\n",
    "            self.imgs = imgs[int(0.8 * imgs_num):]\n",
    "        \n",
    "        \n",
    "        normalize = T.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                    std=[0.5, 0.5, 0.5])\n",
    "\n",
    "        if self.test:\n",
    "            self.transforms = T.Compose([\n",
    "                    T.Resize(600),\n",
    "                    T.CenterCrop(600),\n",
    "\n",
    "                    T.ToTensor(),\n",
    "                    normalize\n",
    "                ])\n",
    "        else:\n",
    "            self.transforms = T.Compose([\n",
    "\n",
    "                        T.ToTensor(),\n",
    "                        normalize\n",
    "                    ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        一次返回一张图片的数据\n",
    "        \"\"\"\n",
    "        img_path = self.imgs[index]\n",
    "        if self.test:\n",
    "            label = img_path\n",
    "        else:\n",
    "            label = int(self.imgs[index].split('/')[-2])\n",
    "        data = Image.open(img_path)\n",
    "        \n",
    "        data = self.transforms(data)\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = models.inception_v3(pretrained=True)\n",
    "# model.fc = nn.Linear(8192,5)\n",
    "# model.AuxLogits.fc = nn.Linear(768, 5)\n",
    "#model.load_state_dict(t.load(opt.load_model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.model_zoo as model_zoo\n",
    "model_zoo.load_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_prob(augment_root, model, batch_size):\n",
    "    '''\n",
    "    input：通过dataloader批量处理的结构化图片数据\n",
    "\n",
    "    output：\n",
    "    probabilities:包含label，与概率值,字典格式\n",
    "\n",
    "    '''\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    test_data = Eye(augment_root, test=True,train=False)\n",
    "    test_dataloader = DataLoader(test_data, batch_size = batch_size, shuffle=False)\n",
    "\n",
    "    #t.no_grad() torch0.4\n",
    "    raw_probabilities = []\n",
    "    for ii,(data, label) in tqdm(enumerate(test_dataloader)):\n",
    "        input = Variable(data)\n",
    "        #label = str(label.numpy().tolist().pop())\n",
    "        \n",
    "\n",
    "        input = input.cuda()\n",
    "        score = model(input)\n",
    "        prob = F.softmax(score,dim=1).data.tolist()\n",
    "        #label = score.max(dim=1)[1].data.tolist()\n",
    "        #label = str(label)\n",
    "        batch_results = [(label_,prob_) for label_,prob_ in zip(label,prob)]\n",
    "        raw_probabilities += batch_results\n",
    "     \n",
    "\n",
    "    #with open('val_cats_prob.txt', 'w') as f:\n",
    "     #   f.write(str(probabilities))\n",
    "    #   f.close()\n",
    "    return raw_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo_root = '/data/health/Xli/original_5class/demo/'\n",
    "raw_pro = get_prob(demo_root, model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#deal with raw_probabilities\n",
    "def deal_probabilities(raw_probabilities):\n",
    "    probabilities = {}\n",
    "    pro_label_list = []\n",
    "    for key in raw_probabilities:\n",
    "        pro_label = key[0].split('/')[-1].split('.')[-2]\n",
    "        if pro_label in pro_label_list:\n",
    "            probabilities[key[0].split('/')[-2] + '/' + pro_label] += [key[1]]\n",
    "        else:\n",
    "            probabilities[key[0].split('/')[-2] + '/'+ pro_label] = [key[1]]\n",
    "            pro_label_list.append(pro_label)\n",
    "    return probabilities\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pro = deal_probabilities(raw_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for key in pro:\n",
    "    if i > 8:\n",
    "        print(key)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_diversity(propabilities):\n",
    "    '''\n",
    "    计算diversity指标\n",
    "    diversity indicates the prediction consistency among the patches within a candidate\n",
    "    higher diversity values denotes higher degrees of prediction inconsistency among \n",
    "    patches within a patch\n",
    "    input：\n",
    "        probabilities：一幅图片的n个augmentation后的patch通过模型后得到的概率值，字典格式\n",
    "    output：\n",
    "        diversity：该图片的diversity,（float）格式\n",
    "    '''\n",
    "    diversity = 0.\n",
    "    m = len(propabilities)\n",
    "    k = len(propabilities[0])\n",
    "    for i in range(m):\n",
    "        for j in range(i + 1, m):\n",
    "            for k in range(k):\n",
    "                diversity += (propabilities[j][k] - propabilities[i][k]) * np.log((propabilities[j][k]+0.00001) / (propabilities[i][k]+0.00001)) \n",
    "    return diversity\n",
    "\n",
    "    \n",
    "\n",
    "def compute_entropy(propabilities):\n",
    "    '''\n",
    "    计算entropy指标\n",
    "    entropy包含一个样本的所有patchs对不同类别的预测概率的熵值之和，其值越高表示越难以分类\n",
    "    input：\n",
    "        probabilities：一幅图片的n个augmentation后的patch通过模型后得到的概率值，字典格式\n",
    "    output：\n",
    "        diversity：该图片的entropy,（float）格式\n",
    "    '''\n",
    "    entropy = 0.\n",
    "    m = len(propabilities)\n",
    "    k = len(propabilities[0])\n",
    "    for i in range(m):\n",
    "        for j in range(k):\n",
    "            entropy += (propabilities[i][j] + 0.00001) * np.log(propabilities[i][j] + 0.00001)\n",
    "    entropy = (-1 / m) * entropy\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pick_hard(lambda_div, lambda_ent, pic_result, augment_now_root, model, batch_size):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "   \n",
    "    #找出指标\n",
    "    probs = get_prob(augment_now_root, model, batch_size)\n",
    "    probs = deal_probabilities(probs)\n",
    "    \n",
    "    for prob in probs:\n",
    "        diversity = compute_diversity(probs[prob])\n",
    "        entropy = compute_entropy(probs[prob])\n",
    "        result = lambda_div * diversity + lambda_ent * entropy\n",
    "        pic_result[prob] = result,diversity,entropy\n",
    "\n",
    "    #将得到结果储存在‘results.txt'中\n",
    "#     with open('demo.txt', 'w') as f:\n",
    "#         f.write(str(pic_result))\n",
    "#         f.close()\n",
    "    #返回最高的前n个\n",
    "#     result_tuple = sorted(pic_result.items(), key=lambda x:x[1][0], reverse=True)\n",
    "#     top1000 = result_tuple[:1000]\n",
    "#     with open('sorted_demo_results.txt', 'w') as f:\n",
    "#         f.write(str(result_tuple))\n",
    "#         f.close()\n",
    "\n",
    "    return pic_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roots = os.listdir(augment_root)\n",
    "pic_result = {}\n",
    "for key in roots:\n",
    "    augment_now_root = os.path.join(augment_root, key)\n",
    "    pic_result = pick_hard(0.5, 0.5, pic_result, augment_now_root, model, 1)\n",
    "    \n",
    "with open('fifth_result.txt', 'w') as f:\n",
    "    f.write(str(pic_result))\n",
    "    f.close()\n",
    "        \n",
    "result_tuple = sorted(pic_result.items(), key=lambda x:x[1][0], reverse=True)\n",
    "with open('sorted_fifth_results.txt', 'w') as f:\n",
    "    f.write(str(result_tuple))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('sorted_fifth_results.txt', 'r') as f:\n",
    "    a = f.read()\n",
    "    a = eval(a)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pick = a[:1500]\n",
    "picked = []\n",
    "for key in pick:\n",
    "    picked.append(key[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "picked = sorted(picked, key=lambda x:int(x.split('/')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "picked[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "picked_0 = []\n",
    "picked_1 = []\n",
    "picked_2 = []\n",
    "picked_3 = []\n",
    "picked_4 = []\n",
    "for key in picked:\n",
    "    if int(key.split('/')[0]) == 0:\n",
    "        picked_0.append(key.split('/')[1])\n",
    "    elif int(key.split('/')[0]) == 1:\n",
    "        picked_1.append(key.split('/')[1])\n",
    "    elif int(key.split('/')[0]) == 2:\n",
    "        picked_2.append(key.split('/')[1])\n",
    "    elif int(key.split('/')[0]) == 3:\n",
    "        picked_3.append(key.split('/')[1])\n",
    "    elif int(key.split('/')[0]) == 4:\n",
    "        picked_4.append(key.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "picked_4[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# move data to train\n",
    "import shutil\n",
    "in_root = '/home/userpython3/Templates/health/Xli/eye_data/augment_train/4/'\n",
    "out_root = '/home/userpython3/Templates/health/Xli/eye_data/picked/fifth/4/'\n",
    "imgs = os.listdir(in_root)\n",
    "for key in imgs:\n",
    "    if key.split('.')[-2] in picked_4:\n",
    "        shutil.move(os.path.join(in_root, key), out_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#查看文件夹包含多少张图片\n",
    "imgs_0 = os.listdir(out_root)\n",
    "len(imgs_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#数据复制\n",
    "in_root_copy = '/home/userpython3/Templates/health/Xli/eye_data/picked/first/4/'\n",
    "out_root_copy= '/home/userpython3/Templates/health/Xli/eye_data/picked/second/4/'\n",
    "imgs = os.listdir(in_root_copy)\n",
    "for img in imgs:\n",
    "    #if 'cat' in img:\n",
    "        #if int(img.split('.')[-2]) in cat1:\n",
    "    shutil.copy(os.path.join(in_root_copy,img), out_root_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_data_root, model, batch_size, lr,epoch_num):\n",
    "    #model\n",
    "    \n",
    "    model.train()\n",
    "    model.cuda()\n",
    "    #data\n",
    "    train_data = Eye(root= train_data_root, train=True)\n",
    "    val_data = Eye(root = train_data_root, train=False)\n",
    "    train_dataloader = DataLoader(train_data, batch_size,shuffle=True,num_workers=4)\n",
    "    val_dataloader = DataLoader(val_data, batch_size=10,shuffle=True, num_workers=4)\n",
    "    #val_dataloader = DataLoader(val_data)\n",
    "    #optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "   \n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=1e-8)\n",
    "    #nn.utils.clip_grad_norm(model.parameters(), 10, norm_type=2)\n",
    "    #train\n",
    "    train_loss_log = []\n",
    "    val_loss_log = []\n",
    "    for epoch in range(epoch_num):\n",
    "        \n",
    "        for ii,(data,label) in tqdm(enumerate(train_dataloader)):\n",
    "                input = Variable(data)\n",
    "                target = Variable(label)\n",
    "\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                score = model(input)\n",
    "                loss = criterion(score,target)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm(model.parameters(), 10, norm_type=2)\n",
    "                optimizer.step()\n",
    "                if ii%500==499:\n",
    "                    print(epoch, loss.item())\n",
    "        train_loss_log.append(loss.item())\n",
    "        \n",
    "        name = str('check_points/fifth_solo_train_') + str(int(epoch)) + str('epoch.pth')\n",
    "        torch.save(model.state_dict(), name)\n",
    "        \n",
    "        val_loss_log.append(val(val_dataloader, model))\n",
    "    #torch.save(model.state_dict(),'eye_first_train.pth')\n",
    "    with open('train_fifth_solo_log.txt', 'w') as f:\n",
    "        f.write(str(train_loss_log))\n",
    "        f.close()\n",
    "    with open('val_fifth_solo_log.txt', 'w') as f:\n",
    "        f.write(str(val_loss_log))\n",
    "        f.close()\n",
    "        #validation loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val(val_dataloader, model):\n",
    "    '''\n",
    "    compute model's loss in validation data\n",
    "    '''\n",
    "    model.eval()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for ii, (data, label) in tqdm(enumerate(val_dataloader)):\n",
    "        data = Variable(data)\n",
    "        target = Variable(label)\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "        score = model(data)\n",
    "        loss = criterion(score,target)\n",
    "    print(loss.item())\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = models.inception_v3(pretrained=True)\n",
    "model.fc = nn.Linear(8192,5)\n",
    "model.aux_logits = False\n",
    "\n",
    "model.load_state_dict(torch.load('check_points/fifth_solo_train_17epoch.pth'))\n",
    "#model.AuxLogits.fc = nn.Linear(37632, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# val_data = Eye(train_root, test=False,train=False)\n",
    "# val_dataloader = DataLoader(val_data, batch_size=10,shuffle=False, num_workers=4)\n",
    "# for ii, (img,label) in tqdm(enumerate(val_dataloader)):\n",
    "    \n",
    "#     if ii >400:\n",
    "#         print(label)\n",
    "#     if ii >410:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A/home/userpython3/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:32: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "\n",
      "1it [00:04,  4.45s/it]\u001b[A\n",
      "2it [00:07,  4.01s/it]\u001b[A\n",
      "3it [00:10,  3.70s/it]\u001b[A\n",
      "4it [00:13,  3.48s/it]\u001b[A\n",
      "5it [00:16,  3.34s/it]\u001b[A\n",
      "6it [00:19,  3.22s/it]\u001b[A\n",
      "7it [00:22,  3.15s/it]\u001b[A\n",
      "8it [00:25,  3.09s/it]\u001b[A\n",
      "9it [00:28,  3.06s/it]\u001b[A\n",
      "10it [00:31,  3.04s/it]\u001b[A\n",
      "11it [00:34,  3.03s/it]\u001b[A\n",
      "12it [00:37,  3.01s/it]\u001b[A\n",
      "13it [00:40,  3.01s/it]\u001b[A\n",
      "14it [00:43,  3.00s/it]\u001b[A\n",
      "15it [00:46,  3.00s/it]\u001b[A\n",
      "16it [00:49,  3.00s/it]\u001b[A\n",
      "17it [00:52,  3.00s/it]\u001b[A\n",
      "18it [00:55,  3.00s/it]\u001b[A\n",
      "19it [00:58,  3.01s/it]\u001b[A\n",
      "20it [01:01,  3.00s/it]\u001b[A\n",
      "21it [01:04,  3.01s/it]\u001b[A\n",
      "22it [01:07,  3.00s/it]\u001b[A\n",
      "23it [01:10,  3.01s/it]\u001b[A\n",
      "24it [01:13,  3.00s/it]\u001b[A\n",
      "25it [01:16,  3.00s/it]\u001b[A\n",
      "26it [01:19,  3.00s/it]\u001b[A\n",
      "27it [01:22,  3.00s/it]\u001b[A\n",
      "28it [01:25,  3.00s/it]\u001b[A\n",
      "29it [01:28,  3.01s/it]\u001b[A\n",
      "30it [01:31,  3.01s/it]\u001b[A\n",
      "31it [01:34,  3.01s/it]\u001b[A\n",
      "32it [01:37,  3.00s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "train_root = '/home/userpython3/Templates/health/Xli/eye_data/picked/fifth/'\n",
    "train(train_root, model, 20, 0.0001, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val(val_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = Variable(torch.Tensor(1,3,600, 600))\n",
    "a = a.cuda()\n",
    "model.cuda()\n",
    "model.train()\n",
    "s = model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(test_root, model,batch_size):\n",
    "    test_data = Eye(test_root, test=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size,shuffle=False, num_workers=4)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    results = []\n",
    "    for ii, (data, label) in tqdm(enumerate(test_dataloader)):\n",
    "        data = Variable(data)\n",
    "        \n",
    "        data = data.cuda()\n",
    "        \n",
    "        score = model(data)\n",
    "        \n",
    "        result = score.max(dim = 1)[1].data.tolist()\n",
    "        batch_results = [result_ for result_ in result ]\n",
    "        results += batch_results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_root = '/home/userpython3/Templates/health/Xli/eye_data/validation/4/'\n",
    "result_0 = test(test_root, model,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l0 = []\n",
    "l1 = []\n",
    "l2 = []\n",
    "l3 = []\n",
    "l4 = []\n",
    "for key in result_0:\n",
    "    if key == 0:\n",
    "        l0.append(key)\n",
    "    elif key == 1:\n",
    "        l1.append(key)\n",
    "    elif key == 2:\n",
    "        l2.append(key)\n",
    "    elif key == 3:\n",
    "        l3.append(key)\n",
    "    elif key == 4:\n",
    "        l4.append(key)\n",
    "            \n",
    "print(len(l0),len(l1),len(l2),len(l3), len(l4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(result_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(2521+7+278+34+17)/3500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_csv(test_root, model,batch_size):\n",
    "    test_data = Eye(test_root, test=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size,shuffle=False, num_workers=4)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    results = []\n",
    "    for ii, (data, label) in tqdm(enumerate(test_dataloader)):\n",
    "        data = Variable(data)\n",
    "        \n",
    "        data = data.cuda()\n",
    "        \n",
    "        score = model(data)\n",
    "        \n",
    "        result = score.max(dim = 1)[1].data.tolist()\n",
    "        batch_results = [(label_.split('/')[-1].split('.')[-2], result_) for label_,result_ in zip(label, result)]\n",
    "        results += batch_results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53576"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_root = '/home/user/data/eye_fundus/original_5class/test/'\n",
    "imgs = os.listdir(kaggle_root)\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_csv(results, file_name):\n",
    "    import csv\n",
    "    with open(file_name, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['image', 'level'])\n",
    "        writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53576it [1:30:13, 11.45it/s]\n"
     ]
    }
   ],
   "source": [
    "results = test_csv(kaggle_root, model,1)\n",
    "write_csv(results, 'kaggle_5_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_csv(results, 'kaggle_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
